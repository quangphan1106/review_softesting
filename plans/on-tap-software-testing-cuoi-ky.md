# T√ÄI LI·ªÜU √îN T·∫¨P CU·ªêI K·ª≤ - SOFTWARE TESTING (CS423)

> **L∆∞u √Ω:** ƒê·ªÅ thi c√≥ 7 c√¢u ·ªü m·ª©c V·∫¨N D·ª§NG (kh√¥ng ph·∫£i ƒë·ªãnh nghƒ©a). T·∫≠p trung v√†o scenarios, so s√°nh tools, v√† gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ th·ª±c t·∫ø.

---

## M·ª§C L·ª§C

1. [CI/CD](#1-cicd)
2. [Performance Testing](#2-performance-testing)
3. [Automation Testing](#3-automation-testing)
4. [GUI & Usability Testing](#4-gui--usability-testing)
5. [API Testing & Mocking](#5-api-testing--mocking)
6. [AI trong Testing](#6-ai-trong-testing)
7. [Database Testing](#7-database-testing)
8. [Domain Testing & Data Generation](#8-domain-testing--data-generation)

---

## 1. CI/CD

### Kh√°i ni·ªám c·ªët l√µi

| Thu·∫≠t ng·ªØ | ƒê·ªãnh nghƒ©a | ƒêi·ªÉm kh√°c bi·ªát |
|-----------|-----------|----------------|
| **CI (Continuous Integration)** | Merge code th∆∞·ªùng xuy√™n, auto build + test | Feedback nhanh, ph√°t hi·ªán l·ªói s·ªõm |
| **CD (Continuous Delivery)** | Code s·∫µn s√†ng deploy, C·∫¶N approve th·ªß c√¥ng | C√≥ human failsafe |
| **Continuous Deployment** | Auto deploy l√™n production | Kh√¥ng c·∫ßn approve, c·∫ßn CI mature |

### 3 C·ªôt tr·ª• CI
1. **SCM (Git)**: GitHub Flow, branch strategy, code review qua PR
2. **Automated Build**: Compile, install dependencies, detect missing files
3. **Automated Testing**: Unit test, lint, security scan, coverage

### GitHub Actions - Components
```yaml
name: CI Pipeline
on: [push, pull_request]
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - run: npm install && npm test
```

### C√¢u h·ªèi v·∫≠n d·ª•ng ti·ªÅm nƒÉng

| Scenario | Tr·∫£ l·ªùi |
|----------|---------|
| "It works on my machine" problem? | Implement CI + Docker + automated tests |
| Khi n√†o d√πng Delivery vs Deployment? | Delivery: high-risk (ng√¢n h√†ng); Deployment: tech company move fast |
| Hardcode password v√†o GitHub? | D√πng GitHub Secrets, inject qua env variables |
| Ch·∫°y test h√†ng ƒë√™m - cron? | `schedule: cron: '0 2 * * *'` |

---

## 2. PERFORMANCE TESTING

### 6 Lo·∫°i Performance Testing

| Lo·∫°i | M·ª•c ƒë√≠ch | Pattern | V√≠ d·ª• |
|------|----------|---------|-------|
| **Load Testing** | Test t·∫°i expected load | Ramp-up d·∫ßn | 100 users b√¨nh th∆∞·ªùng |
| **Stress Testing** | T√¨m breaking point | V∆∞·ª£t capacity | 10,000 users ƒë·∫øn khi fail |
| **Spike Testing** | Recovery sau sudden load | Jump nhanh | Flash sale: 50‚Üí5000 users |
| **Endurance/Soak** | ·ªîn ƒë·ªãnh d√†i h·∫°n | Steady 24h+ | Detect memory leaks |
| **Volume Testing** | Large data volume | DB 100M rows | Query performance |
| **Scalability** | Linear scaling? | Add resources | 500‚Üí5000 users + nodes |

### Key Metrics

| Metric | √ù nghƒ©a | C√¥ng th·ª©c |
|--------|---------|-----------|
| **Response Time** | Th·ªùi gian response | ms |
| **Throughput** | Requests/sec | TP = Requests / Time |
| **Error Rate** | % failed requests | (Failed/Total) √ó 100% |
| **Percentiles** | p90, p95, p99 | Quan tr·ªçng h∆°n averages |

### Tools So s√°nh

| Tool | Language | ∆Øu ƒëi·ªÉm | Best for |
|------|----------|---------|----------|
| **JMeter** | Java/GUI | Multi-protocol, plugins nhi·ªÅu | Enterprise, complex workflows |
| **k6** | JavaScript/Go | Performance cao, CI/CD friendly | DevOps, modern web APIs |
| **Locust** | Python | D·ªÖ h·ªçc, web UI | Python teams |
| **Gatling** | Scala | High-throughput, HTML reports | Scala/Java teams |

### JMeter Components
- **Thread Group**: Virtual users, ramp-up, loops
- **Samplers**: HTTP Request, JDBC Request
- **Timers**: Think time (realistic delays)
- **Assertions**: Check response status, JSON path
- **Listeners**: View Results, Aggregate Report

### C√¢u h·ªèi v·∫≠n d·ª•ng

| Scenario | Tr·∫£ l·ªùi |
|----------|---------|
| Setup Load Test cho login API? | Define goals (RT<2s, Error<1%), 100 users, 30s ramp-up, CSV test data, assertions |
| Stress vs Load Test kh√°c g√¨? | Load: expected load, <1% errors; Stress: beyond capacity, t√¨m breaking point |
| Response time 700ms nh∆∞ng 84% error rate? | Error rate critical, likely auth issue kh√¥ng ph·∫£i performance |
| Detect memory leak nh∆∞ th·∫ø n√†o? | Endurance test 24h+, monitor heap grows |

---

## 3. AUTOMATION TESTING

### Desktop vs Web Automation

| Kh√≠a c·∫°nh | Desktop | Web |
|-----------|---------|-----|
| Target | OS-installed apps | Browser-based |
| Tools | Pywinauto, WinAppDriver | Selenium, Playwright, Cypress |
| Interaction | Win32 API, GUI controls | DOM, CSS selectors |

### Selenium Core Concepts

**Locators (QUAN TR·ªåNG):**
| Locator | M√¥ t·∫£ | V√≠ d·ª• |
|---------|-------|-------|
| id | By ID attribute | `driver.find_element(By.ID, "login")` |
| xpath | XPath expression | `//button[@text='Submit']` |
| css selector | CSS selector | `.btn-primary` |
| link text | Anchor text | `driver.find_element(By.LINK_TEXT, "Click")` |

**Waits (C·ª∞C K·ª≤ QUAN TR·ªåNG):**

| Lo·∫°i | C√°ch d√πng | V·∫•n ƒë·ªÅ |
|------|-----------|--------|
| `Thread.sleep()` | ‚ùå TR√ÅNH | Slow, flaky, wastes time |
| **Implicit Wait** | Set once for driver | Ch·ªâ check "present?", kh√¥ng check visible |
| **Explicit Wait** | Wait for specific condition | ‚úÖ BEST: visibility, clickability |

```python
# Explicit Wait example
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

wait = WebDriverWait(driver, 10)
element = wait.until(EC.visibility_of_element_located((By.ID, "login")))
```

**Page Object Model (POM):**
- Separate class cho m·ªói page
- Ch·ª©a locators + methods
- Benefits: Reusability, maintainability

### Common Challenges & Solutions

| Problem | Solution |
|---------|----------|
| Dynamic IDs (`id="ember4661"`) | Use stable text/labels as anchor |
| iFrame | `driver.switch_to.frame("frame_id")` |
| Captcha/OTP | Disable in test env, static OTP |
| Flaky tests | Explicit waits, stable locators |

### C√¢u h·ªèi v·∫≠n d·ª•ng

| Scenario | Tr·∫£ l·ªùi |
|----------|---------|
| T·∫°i sao kh√¥ng d√πng Thread.sleep()? | Slow + flaky. D√πng implicit/explicit waits |
| Dynamic ID problem? | Use Stable Neighbor Strategy - locate by text/labels |
| POM l√† g√¨? Benefits? | Design pattern: separate page classes, reusability |
| Khi n√†o n√™n automate? | Regression, smoke, repetitive tests. KH√îNG: unstable UI, ad-hoc |

---

## 4. GUI & USABILITY TESTING

### GUI vs UI vs UX

| Term | Scope | Focus |
|------|-------|-------|
| **UI** | T·∫•t c·∫£ interface (voice, gesture, touch) | Ph∆∞∆°ng th·ª©c t∆∞∆°ng t√°c |
| **GUI** | ƒê·ªì h·ªça (buttons, menus, icons) | Visual elements |
| **Usability** | D·ªÖ s·ª≠ d·ª•ng | Efficiency, effectiveness, satisfaction |
| **UX** | To√†n b·ªô tr·∫£i nghi·ªám | Emotions, attitudes |

### GUI Checklist - 4 Categories

| Category | Check items |
|----------|-------------|
| **Colors** | Contrast, consistency, distinguishing states |
| **Content** | Font consistency, alignment, spelling |
| **Images** | Display correctly, alignment, sizing |
| **Forms** | Labels, input states, radio/checkbox logic |

### Tools

| Tool | Purpose | Pros | Cons |
|------|---------|------|------|
| **Selenium** | Automation, CSS checks | Free, reads raw code | Brittle, no visual testing |
| **Playwright** | Cross-browser local | 3 engines √ó 3 form factors | Local only |
| **BrowserStack** | Real devices cloud | 3000+ devices | Paid, 1-min free limit |
| **Applitools** | AI Visual Testing | Smart comparison | Paid |
| **Lookback.io** | UX recording | Screen + voice + facial | 5 session limit |

### Traditional vs AI-First UI Testing

| Aspect | Traditional | AI-First |
|--------|-------------|----------|
| Element recognition | Fixed locators (XPath, CSS) | Visual, semantic, contextual |
| Stability | Brittle | Adaptive |
| Validation | Rule-based assertions | Smart/visual assertions |
| Bug detection | Only explicitly coded | Visual bugs, layout shifts |

### C√¢u h·ªèi v·∫≠n d·ª•ng

| Scenario | Tr·∫£ l·ªùi |
|----------|---------|
| 200+ products, check CO2 badge colors? | Selenium + Python automation |
| Cross-browser strategy? | Playwright (3 engines √ó 3 form factors) + BrowserStack (real devices) |
| Broken links on 1000+ pages? | Sitebulb (full site crawler), kh√¥ng Check My Links (1 page) |
| Checkout flow user feelings? | Lookback.io (screen + audio + facial) |

---

## 5. API TESTING & MOCKING

### 5 Lo·∫°i API Testing

| Lo·∫°i | Purpose | V√≠ d·ª• |
|------|---------|-------|
| **Functional** | API ho·∫°t ƒë·ªông theo spec | Login: 200 + token, 401 sai password |
| **Load** | Performance d∆∞·ªõi t·∫£i | 1000 users, 95% < 300ms |
| **Security** | Auth, vulnerabilities | SQL injection, XSS |
| **Contract** | Schema ƒë√∫ng spec | Field types, required fields |
| **Integration** | Multiple systems | Order ‚Üí Payment ‚Üí Inventory |

### Postman Components

| Component | Purpose |
|-----------|---------|
| **API Requests** | GET, POST, PUT, DELETE |
| **Pre-request Script** | Setup: generate UUID, set headers |
| **Post-request Script** | Validate: status, extract token |
| **Collections** | Group related requests |
| **Environment Variables** | Store URLs, tokens (Dev/Prod) |

### API Mocking

**4 Lo·∫°i Mocking:**
| Type | Description | Use case |
|------|-------------|----------|
| **Static** | Fixed response | Early UI dev |
| **Dynamic** | Response varies by input | Different workflows |
| **Contract-based** | From OpenAPI/Swagger | Schema alignment |
| **Behavior-driven** | Simulate conditions | Timeouts, failures |

**Benefits:** Parallel development, stable testing, early bug detection

### C√¢u h·ªèi v·∫≠n d·ª•ng

| Scenario | Tr·∫£ l·ªùi |
|----------|---------|
| Frontend c·∫ßn work tr∆∞·ªõc backend ready? | API Mocking (Static/Dynamic) |
| Pre-request vs Post-request Script? | Pre: setup headers/data; Post: validate + extract token |
| API accepts invalid format? | Negative Test / Boundary Test |
| Khi n√†o Contract Testing? | Microservices, ensure schema alignment |

---

## 6. AI TRONG TESTING

### 2 Mi·ªÅn Ri√™ng Bi·ªát

| Mi·ªÅn | M√¥ t·∫£ | Tools |
|------|-------|-------|
| **AI-Powered Testing** | D√πng AI c·∫£i thi·ªán testing | UnitTestAI, Qodo, Healenium |
| **Testing AI Systems** | Test h·ªá th·ªëng AI/ML | OpenAI Evals, custom frameworks |

### AI Testing Tools

| Tool | Function |
|------|----------|
| **Self-Healing** (Healenium) | Auto-fix locators khi UI thay ƒë·ªïi |
| **Intelligent Test Gen** | Sinh test case t·ª´ user actions |
| **Visual AI** (Applitools) | Compare baseline vs current screenshot |
| **Postbot** | Write tests, visualize responses |

### Test Oracle Problem (QUAN TR·ªåNG)

**V·∫•n ƒë·ªÅ:** AI sinh input + execute code, NH∆ØNG kh√¥ng bi·∫øt output ƒê√öNG l√† g√¨
- AI c√≥ th·ªÉ write test pass bugs (treat bug nh∆∞ "correct")
- 100% coverage ‚â† 100% bug-free

**Gi·∫£i ph√°p:** Paradigm shift: "Test Author" ‚Üí "Test Auditor"
- AI generates, humans verify INTENT

### Testing AI Systems - Categories

| Category | Focus |
|----------|-------|
| **Functional** | Accuracy, Precision, Recall, F1 |
| **Performance** | Inference latency, throughput |
| **Robustness** | Adversarial examples, noise |
| **Fairness** | Bias detection, demographic parity |
| **Safety** | Prompt injection, data poisoning |

### C√¢u h·ªèi v·∫≠n d·ª•ng

| Scenario | Tr·∫£ l·ªùi |
|----------|---------|
| Test Oracle Problem l√† g√¨? | AI kh√¥ng bi·∫øt output ƒë√∫ng, c√≥ th·ªÉ pass bugs |
| AI testing limitation? | Misinterpret docs, limited business rules, needs human review |
| Deterministic vs Probabilistic? | Traditional: same input ‚Üí same output; AI: same input ‚Üí different outputs |
| Self-healing tests? | Healenium: AI learns elements, auto-fix locators |

---

## 7. DATABASE TESTING

### 3 Lo·∫°i DB Testing

| Lo·∫°i | Focus | Examples |
|------|-------|----------|
| **Structural** | Schema, constraints | Table validation, indexes, FK |
| **Functional** | CRUD operations | SELECT, INSERT, UPDATE, DELETE |
| **Non-Functional** | Performance, security | Load test, SQL injection |

### ACID Properties (C·ª∞C K·ª≤ QUAN TR·ªåNG)

| Property | Meaning | Test |
|----------|---------|------|
| **Atomicity** | All or nothing | Multi-INSERT: all or rollback |
| **Consistency** | Valid state ‚Üí valid state | Constraints maintained |
| **Isolation** | Concurrent txns don't interfere | No dirty reads |
| **Durability** | Committed changes persist | Survive crashes |

### Index Testing

**Trade-off:**
- ‚úÖ TƒÉng t·ªëc SELECT (Read)
- ‚ùå Gi·∫£m t·ªëc INSERT/UPDATE/DELETE (Write)

**Test activities:**
- Compare queries WITH vs WITHOUT indexes
- Verify indexes on frequently filtered columns
- Check composite index column order

### Tools

| Tool | Purpose |
|------|---------|
| **DBUnit** | Test data setup, assertions |
| **Maven** | Build automation, dependencies |
| **Mockaroo** | Generate realistic test data |

### C√¢u h·ªèi v·∫≠n d·ª•ng

| Scenario | Tr·∫£ l·ªùi |
|----------|---------|
| Test ACID properties? | Multi-INSERT transaction: all commit or all rollback |
| Index trade-offs? | Faster SELECT, slower INSERT/UPDATE/DELETE |
| Migration testing? | Validate data types, relationships, integrity preserved |
| SQL injection test? | Input malicious SQL, verify rejection |

---

## 8. DOMAIN TESTING & DATA GENERATION

### Domain Testing - 4 B∆∞·ªõc

1. **Identify Variables**: Input/Output c·ªßa feature
2. **Equivalence Classes**: Chia th√†nh Valid/Invalid classes
3. **Select Test Cases**: 1 ƒë·∫°i di·ªán t·ª´ m·ªói EC
4. **Boundary Value Analysis**: Test gi√° tr·ªã bi√™n

### Boundary Value Analysis

**Password 8-50 k√Ω t·ª±:**
| Boundary | Values to test |
|----------|----------------|
| Lower | 7, 8, 9 |
| Upper | 49, 50, 51 |

**Stock 0-10,000:**
| Boundary | Values to test |
|----------|----------------|
| Lower | -1, 0, 1 |
| Upper | 9999, 10000, 10001 |

### Data Generation v·ªõi Faker

**Key concepts:**
- `Faker.seed(42)`: Reproducibility
- Realistic data > random strings
- Hierarchical: Categories ‚Üí Products ‚Üí Transactions

**Example fields:**
| Field | Range/Logic |
|-------|-------------|
| Price | 2.00-500.00 (2 decimals) |
| Stock | 0-100 integer |
| DOB | 1970-2005 (age 20-55) |
| Role | 5:1 user:admin ratio |

### C√¢u h·ªèi v·∫≠n d·ª•ng

| Scenario | Tr·∫£ l·ªùi |
|----------|---------|
| BVA cho password 8-50 k√Ω t·ª±? | Test: 7, 8, 9, 49, 50, 51 |
| Faker.seed(42) ƒë·ªÉ l√†m g√¨? | Reproducibility - c√πng data m·ªói l·∫ßn ch·∫°y |
| EC vs BVA kh√°c g√¨? | EC: chia classes; BVA: test edges (b·ªï sung) |
| 1000 transactions, 50 users? | Random user_id(1-50), m·ªói user ~20 txns |

---

## CHECKLIST √îN T·∫¨P

### C√¥ng th·ª©c c·∫ßn nh·ªõ
```
Throughput = Requests / Time (seconds)
Error Rate = (Failed / Total) √ó 100%
Bug Coverage = (Bugs Detected / Total Bugs) √ó 100%
Code Coverage = (Lines Executed / Total Lines) √ó 100%
```

### Tools Summary

| Domain | Tools |
|--------|-------|
| CI/CD | GitHub Actions, Jenkins |
| Performance | JMeter, k6, Locust, Gatling |
| Web Automation | Selenium, Playwright, Cypress |
| Desktop Automation | Pywinauto, WinAppDriver |
| GUI Testing | Selenium, Applitools, BrowserStack |
| API Testing | Postman, WireMock |
| AI Testing | Healenium, Applitools, UnitTestAI, Qodo |
| DB Testing | DBUnit, Maven, Mockaroo |

### Keywords ti·∫øng Anh quan tr·ªçng
- **Throughput** = S·ªë requests/sec
- **Latency** = ƒê·ªô tr·ªÖ
- **Ramp-up** = TƒÉng load d·∫ßn
- **Think Time** = Th·ªùi gian ƒë·ª£i user
- **Percentile** = p90, p95, p99
- **Locator** = XPath, CSS selector, ID
- **Assertion** = Ki·ªÉm tra k·∫øt qu·∫£
- **Fixture** = Setup/teardown
- **Flaky test** = Test kh√¥ng ·ªïn ƒë·ªãnh

---

## C·∫§U TR√öC TR·∫¢ L·ªúI ƒê·ªÄ THI

### M·∫´u tr·∫£ l·ªùi Scenario

```
1. X√ÅC ƒê·ªäNH V·∫§N ƒê·ªÄ
   - [M√¥ t·∫£ ng·∫Øn g·ªçn scenario]

2. PH√ÇN T√çCH
   - [C√°c y·∫øu t·ªë c·∫ßn xem x√©t]
   - [So s√°nh options n·∫øu c√≥]

3. GI·∫¢I PH√ÅP
   - [Ch·ªçn approach/tool c·ª• th·ªÉ]
   - [Gi·∫£i th√≠ch T·∫†I SAO]

4. IMPLEMENTATION (n·∫øu c·∫ßn)
   - [Steps c·ª• th·ªÉ]
   - [Code snippet n·∫øu relevant]
```

---

**Ch√∫c √¥n t·∫≠p t·ªët!** üéØ
