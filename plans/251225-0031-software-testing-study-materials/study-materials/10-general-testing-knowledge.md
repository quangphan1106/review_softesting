# Topic 10: General Software Testing Knowledge
**CS423 Software Testing | Final Exam Preparation**

---

## 1. Software Development Life Cycle (SDLC) & Testing

### 1.1 SDLC Models Overview

**Waterfall Model:**
```
Requirements â†’ Design â†’ Implementation â†’ Testing â†’ Deployment â†’ Maintenance
     â†“            â†“           â†“             â†“          â†“            â†“
  (Sequential, no going back - high risk of late defect discovery)
```
- Testing happens AFTER development complete
- Late defect detection = expensive fixes
- Best for: Fixed requirements, well-understood projects

**V-Model (Verification & Validation):**
```
Requirements    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>  Acceptance Testing
      â†“                                               â†‘
System Design   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>  System Testing
      â†“                                          â†‘
Architecture    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>  Integration Testing
      â†“                                     â†‘
Module Design   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>  Unit Testing
      â†“                              â†‘
      â””â”€â”€â”€â”€â”€â”€>  Coding  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
- Each dev phase has corresponding test phase
- Test planning starts early (left side)
- Test execution happens on right side

**Agile/Scrum Model:**
```
Sprint 1          Sprint 2          Sprint 3
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Plan     â”‚     â”‚ Plan     â”‚     â”‚ Plan     â”‚
â”‚ Develop  â”‚ â”€â”€> â”‚ Develop  â”‚ â”€â”€> â”‚ Develop  â”‚ â”€â”€> ...
â”‚ Test     â”‚     â”‚ Test     â”‚     â”‚ Test     â”‚
â”‚ Review   â”‚     â”‚ Review   â”‚     â”‚ Review   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   2-4 weeks        2-4 weeks        2-4 weeks
```
- Iterative & incremental
- Testing integrated throughout each sprint
- Continuous feedback and adaptation

### 1.2 Testing in Agile

**Agile Testing Quadrants:**
```
                    Business-Facing
                         â†‘
           Q2                      Q3
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Functional Testsâ”‚  Exploratory    â”‚
    â”‚ Examples        â”‚  Usability      â”‚
    â”‚ Story Tests     â”‚  UAT            â”‚
    â”‚ Prototypes      â”‚  Alpha/Beta     â”‚
    â”‚                 â”‚                 â”‚
    â”‚ Support Team    â”‚ Critique Productâ”‚
â†â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â†’
    â”‚ Guide Dev       â”‚ Critique Productâ”‚ Automated
    â”‚                 â”‚                 â”‚
    â”‚ Unit Tests      â”‚  Performance    â”‚
    â”‚ Component Tests â”‚  Load Testing   â”‚
    â”‚ Integration     â”‚  Security       â”‚
           Q1                      Q4
                         â†“
                  Technology-Facing
```

**Scrum Testing Activities:**
- **Sprint Planning**: Estimate testing effort, define DoD
- **Daily Standup**: Report testing progress/blockers
- **Sprint Execution**: Continuous testing, automation
- **Sprint Review**: Demo working software
- **Retrospective**: Improve testing process

**Definition of Done (DoD) - Testing Checklist:**
```markdown
â–¡ Unit tests written and passing (>80% coverage)
â–¡ Integration tests passing
â–¡ Code reviewed and approved
â–¡ No critical/high severity bugs open
â–¡ Regression tests executed
â–¡ Documentation updated
â–¡ Performance benchmarks met
```

---

## 2. Test Levels (Test Pyramid)

### 2.1 Test Pyramid

```
                    â–²
                   /â”‚\
                  / â”‚ \      E2E/UI Tests (Few, Slow, Expensive)
                 /  â”‚  \     - Full system validation
                /   â”‚   \    - Browser automation
               /â”€â”€â”€â”€â”¼â”€â”€â”€â”€\
              /     â”‚     \  Integration Tests (Medium)
             /      â”‚      \ - API testing
            /       â”‚       \- Component interaction
           /â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€\
          /         â”‚         \  Unit Tests (Many, Fast, Cheap)
         /          â”‚          \ - Individual functions
        /           â”‚           \- Isolated, no dependencies
       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### 2.2 Test Levels Detailed

**Level 1: Unit Testing**
- Tests individual functions/methods in isolation
- Written by developers
- Fastest execution, easiest to debug
- Tools: JUnit, pytest, Jest, NUnit

```python
# Unit Test Example
def test_calculate_discount():
    # Arrange
    price = 100
    discount_percent = 20

    # Act
    result = calculate_discount(price, discount_percent)

    # Assert
    assert result == 80
```

**Level 2: Integration Testing**
- Tests interaction between components/modules
- Verifies interfaces, data flow
- Types: Big Bang, Top-Down, Bottom-Up, Sandwich

```
Top-Down Integration:
    [Module A] (tested first with stubs)
       â†“
    [Module B] (stub replaced, tested)
       â†“
    [Module C] (stub replaced, tested)

Bottom-Up Integration:
    [Module C] (tested first with drivers)
       â†‘
    [Module B] (driver replaced, tested)
       â†‘
    [Module A] (driver replaced, tested)
```

**Level 3: System Testing**
- Tests complete integrated system
- Validates functional & non-functional requirements
- Black-box testing approach
- Environment similar to production

**Level 4: Acceptance Testing**
- **UAT (User Acceptance Testing)**: End-users validate business requirements
- **Alpha Testing**: Internal testing at developer's site
- **Beta Testing**: External testing by real users
- **Contract/Regulation Testing**: Compliance verification

---

## 3. Test Types Classification

### 3.1 Functional vs Non-Functional

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SOFTWARE TESTING                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     FUNCTIONAL           â”‚         NON-FUNCTIONAL              â”‚
â”‚  (What system does)      â”‚      (How system performs)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Unit Testing           â”‚ â€¢ Performance Testing               â”‚
â”‚ â€¢ Integration Testing    â”‚ â€¢ Load Testing                      â”‚
â”‚ â€¢ System Testing         â”‚ â€¢ Stress Testing                    â”‚
â”‚ â€¢ Regression Testing     â”‚ â€¢ Security Testing                  â”‚
â”‚ â€¢ Smoke Testing          â”‚ â€¢ Usability Testing                 â”‚
â”‚ â€¢ Sanity Testing         â”‚ â€¢ Compatibility Testing             â”‚
â”‚ â€¢ UAT                    â”‚ â€¢ Reliability Testing               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Smoke vs Sanity Testing

| Aspect | Smoke Testing | Sanity Testing |
|--------|---------------|----------------|
| **Purpose** | Verify build stability | Verify specific functionality |
| **Scope** | Broad, shallow | Narrow, deep |
| **When** | After new build | After bug fix/minor change |
| **Coverage** | Critical paths only | Specific module/feature |
| **Performed by** | Developers/QA | Usually QA |
| **Build rejection** | Yes, if fails | No, only module rejected |
| **Also called** | Build Verification Test | Subset of regression |

```
SMOKE TEST:                          SANITY TEST:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Login âœ“            â”‚              â”‚                     â”‚
â”‚  Dashboard loads âœ“  â”‚              â”‚  Search Module      â”‚
â”‚  Navigation works âœ“ â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  Basic CRUD âœ“       â”‚              â”‚  â”‚ Search A âœ“    â”‚  â”‚
â”‚  Logout âœ“           â”‚              â”‚  â”‚ Search B âœ“    â”‚  â”‚
â”‚                     â”‚              â”‚  â”‚ Filter X âœ“    â”‚  â”‚
â”‚ (Surface level all) â”‚              â”‚  â”‚ Sort Y âœ“      â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                     â”‚ (Deep dive one area)â”‚
                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3 Regression Testing

**Definition:** Re-testing after code changes to ensure existing functionality still works

**When to perform:**
- After bug fixes
- After new feature additions
- After code refactoring
- After configuration changes
- After environment changes

**Regression Test Selection Strategies:**
1. **Retest All**: Run entire test suite (expensive but thorough)
2. **Selective**: Choose tests based on changed areas
3. **Priority-based**: Run high-priority tests first
4. **Risk-based**: Focus on high-risk areas

```
Code Change Impact Analysis:
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Module A â”‚ â† Change here
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                         â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â†“            â†“            â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Module B â”‚ â”‚ Module C â”‚ â”‚ Module D â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†‘            â†‘            â†‘
        Must test    Must test    Must test
```

### 3.4 Exploratory Testing

**Definition:** Simultaneous learning, test design, and test execution

**Session-Based Test Management (SBTM):**
```
Session Charter: Explore [feature] with [resources] to discover [information]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Session: Payment Processing                                 â”‚
â”‚ Duration: 90 minutes                                        â”‚
â”‚ Tester: John Doe                                           â”‚
â”‚ Charter: Explore checkout flow with invalid payment methods â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Notes:                                                      â”‚
â”‚ - Found issue with expired card handling                   â”‚
â”‚ - Edge case: switching payment method mid-checkout         â”‚
â”‚ - Question: What happens with 3D Secure timeout?           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Bugs Found: 3 | Questions: 2 | Test Ideas: 5               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.5 Other Important Test Types

**Alpha Testing:**
- Internal testing at developer's site
- By internal employees (not dev team)
- Before beta release

**Beta Testing:**
- External testing at customer's site
- By real end-users
- Feedback collected for improvement

**Ad-hoc Testing:**
- Informal, unplanned testing
- No documentation
- Based on tester's intuition

**Monkey Testing:**
- Random inputs and actions
- No expected results
- Goal: Crash the system

**Gorilla Testing:**
- Repeatedly test one module
- Heavy load on specific functionality
- Stress specific component

---

## 4. Test Documentation

### 4.1 Test Plan Structure (IEEE 829)

```markdown
# Test Plan: [Project Name]

## 1. Test Plan Identifier
TP-PROJECT-001-v1.0

## 2. Introduction
Purpose and scope of testing

## 3. Test Items
- Feature A v1.2
- Feature B v2.0
- Module C v1.0

## 4. Features to be Tested
- User authentication
- Payment processing
- Report generation

## 5. Features NOT to be Tested
- Legacy admin panel (out of scope)
- Third-party integrations

## 6. Approach
- Test levels: Unit, Integration, System
- Test types: Functional, Performance, Security
- Automation strategy

## 7. Pass/Fail Criteria
- All critical tests must pass
- No open P1/P2 bugs
- Code coverage > 80%

## 8. Suspension/Resumption Criteria
Suspend if: Build failure, environment down
Resume when: Issues resolved

## 9. Test Deliverables
- Test cases
- Test scripts
- Test reports
- Defect reports

## 10. Testing Tasks & Schedule
| Task | Start | End | Owner |
|------|-------|-----|-------|
| Unit Testing | Week 1 | Week 2 | Dev Team |
| Integration | Week 3 | Week 4 | QA Team |

## 11. Environment Requirements
- Server: Ubuntu 22.04, 16GB RAM
- Database: PostgreSQL 15
- Browser: Chrome 120+

## 12. Responsibilities
- Test Manager: Overall coordination
- Test Lead: Test design, review
- Testers: Execution, reporting

## 13. Risks & Contingencies
| Risk | Mitigation |
|------|------------|
| Resource shortage | Cross-training |
| Environment delay | Use staging |

## 14. Approvals
- QA Manager: ___________
- Project Manager: ___________
```

### 4.2 Test Case Template

```markdown
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test Case ID: TC-LOGIN-001                                  â”‚
â”‚ Test Case Name: Verify successful login with valid creds    â”‚
â”‚ Module: Authentication                                      â”‚
â”‚ Priority: High | Severity: Critical                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Preconditions:                                              â”‚
â”‚ - User account exists in system                             â”‚
â”‚ - User is on login page                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Test Data:                                                  â”‚
â”‚ - Username: testuser@example.com                            â”‚
â”‚ - Password: ValidPass123!                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Steps:                                                      â”‚
â”‚ 1. Navigate to login page                                   â”‚
â”‚ 2. Enter username in email field                            â”‚
â”‚ 3. Enter password in password field                         â”‚
â”‚ 4. Click "Login" button                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Expected Result:                                            â”‚
â”‚ - User redirected to dashboard                              â”‚
â”‚ - Welcome message displayed                                 â”‚
â”‚ - Session created                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Actual Result: ___________________                          â”‚
â”‚ Status: Pass / Fail / Blocked                               â”‚
â”‚ Tested By: ___________ Date: ___________                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.3 Test Summary Report

```markdown
# Test Summary Report

## Project: E-Commerce Platform v2.0
## Test Period: Dec 1-20, 2024

### Executive Summary
Testing completed with 95% pass rate. 3 critical bugs found and fixed.
System ready for production with minor known issues.

### Test Metrics
| Metric | Value |
|--------|-------|
| Total Test Cases | 450 |
| Executed | 445 |
| Passed | 422 |
| Failed | 18 |
| Blocked | 5 |
| Pass Rate | 94.8% |

### Defect Summary
| Severity | Found | Fixed | Open |
|----------|-------|-------|------|
| Critical | 3 | 3 | 0 |
| High | 8 | 7 | 1 |
| Medium | 15 | 12 | 3 |
| Low | 10 | 5 | 5 |

### Test Coverage
- Functional: 95%
- Regression: 100%
- Performance: 85%
- Security: 80%

### Known Issues (Deferred)
1. Minor UI alignment on Safari mobile
2. Slow report generation (>5000 records)

### Recommendation
âœ… APPROVED for production release
```

---

## 5. Test Techniques Overview

### 5.1 Black-Box Techniques

| Technique | Description | Use Case |
|-----------|-------------|----------|
| **Equivalence Partitioning** | Divide inputs into equivalent classes | Reduce test cases |
| **Boundary Value Analysis** | Test at boundaries of partitions | Find off-by-one errors |
| **Decision Table** | Test combinations of conditions | Complex business rules |
| **State Transition** | Test state changes | Workflow testing |
| **Use Case Testing** | Test user scenarios | End-to-end flows |

### 5.2 White-Box Techniques

| Technique | Description | Coverage |
|-----------|-------------|----------|
| **Statement Coverage** | Every statement executed | Basic |
| **Branch/Decision** | Every decision outcome | Medium |
| **Condition Coverage** | Every condition true/false | Higher |
| **Path Coverage** | All possible paths | Highest |
| **MC/DC** | Modified condition/decision | Aviation/Safety |

```
Code Example:
if (a > 0 AND b > 0):    # Decision with 2 conditions
    print("Positive")
else:
    print("Not positive")

Statement Coverage: 2 tests (one for each print)
Branch Coverage: 2 tests (true path, false path)
Condition Coverage: 4 combinations (a,b: T/T, T/F, F/T, F/F)
```

---

## 6. Quality Metrics

### 6.1 Test Metrics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     TEST METRICS                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PROCESS METRICS          â”‚ PRODUCT METRICS                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Test case execution    â”‚ â€¢ Defect density                â”‚
â”‚   rate                   â”‚   (defects/KLOC)                â”‚
â”‚ â€¢ Test coverage %        â”‚ â€¢ Defect removal efficiency     â”‚
â”‚ â€¢ Defect detection rate  â”‚ â€¢ Mean time to failure          â”‚
â”‚ â€¢ Test efficiency        â”‚ â€¢ Customer-found defects        â”‚
â”‚ â€¢ Automation ROI         â”‚ â€¢ Code coverage %               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Formulas:**

```
Defect Density = Total Defects / Size (KLOC or FP)

Defect Removal Efficiency (DRE) =
    (Defects found during testing / Total defects) Ã— 100%

Test Case Effectiveness =
    (Defects found by test cases / Total test cases executed) Ã— 100%

Automation ROI =
    (Manual cost - Automation cost) / Automation cost Ã— 100%

Test Coverage =
    (Requirements covered by tests / Total requirements) Ã— 100%
```

### 6.2 Defect Life Cycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   NEW   â”‚â”€â”€â”€>â”‚  ASSIGNEDâ”‚â”€â”€â”€>â”‚   OPEN   â”‚â”€â”€â”€>â”‚  FIXED   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                    â”‚                               â”‚
                    â–¼                               â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ DUPLICATEâ”‚                   â”‚ VERIFIED â”‚
              â”‚ REJECTED â”‚                   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
              â”‚ DEFERRED â”‚                        â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                                         â–¼                 â–¼
                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                   â”‚  CLOSED  â”‚      â”‚ REOPENED â”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Defect Report Template:**

```markdown
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Defect ID: BUG-2024-0123                                    â”‚
â”‚ Title: Login fails with special characters in password      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Severity: High          Priority: P1                        â”‚
â”‚ Status: Open            Assigned To: dev@company.com        â”‚
â”‚ Found In: v2.1.0        Environment: Production             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Steps to Reproduce:                                         â”‚
â”‚ 1. Go to login page                                         â”‚
â”‚ 2. Enter email: test@example.com                            â”‚
â”‚ 3. Enter password: P@ss#word!                               â”‚
â”‚ 4. Click Login                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Expected: User logs in successfully                         â”‚
â”‚ Actual: Error "Invalid credentials" displayed               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Attachments: screenshot.png, console_log.txt                â”‚
â”‚ Reporter: qa@company.com    Date: 2024-12-20               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. Manual vs Automation Testing

### 7.1 When to Use Each

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MANUAL TESTING                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ“ Exploratory testing                                       â”‚
â”‚ âœ“ Usability/UX evaluation                                   â”‚
â”‚ âœ“ Ad-hoc testing                                           â”‚
â”‚ âœ“ One-time tests                                           â”‚
â”‚ âœ“ Visual validation                                        â”‚
â”‚ âœ“ Complex scenarios hard to automate                        â”‚
â”‚ âœ“ Short-term projects                                      â”‚
â”‚ âœ“ Early development (unstable UI)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AUTOMATION TESTING                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ“ Regression testing                                        â”‚
â”‚ âœ“ Load/Performance testing                                  â”‚
â”‚ âœ“ Repetitive tests                                         â”‚
â”‚ âœ“ Data-driven testing                                      â”‚
â”‚ âœ“ Cross-browser/platform testing                           â”‚
â”‚ âœ“ CI/CD pipeline integration                               â”‚
â”‚ âœ“ Long-term projects                                       â”‚
â”‚ âœ“ Stable features                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 Automation ROI Calculation

```
Break-even point = Automation Cost / (Manual Cost - Maintenance Cost)

Example:
- Manual test cost per run: $100
- Automation development: $2000
- Maintenance per run: $10
- Tests run per year: 50

ROI = (50 Ã— $100 - $2000 - 50 Ã— $10) / $2000 Ã— 100%
ROI = ($5000 - $2000 - $500) / $2000 Ã— 100%
ROI = 125%

Break-even: $2000 / ($100 - $10) = 22.2 runs
â†’ After 23 runs, automation starts saving money
```

---

## 8. Test Environment & Configuration

### 8.1 Environment Types

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DEV        â†’    QA/TEST    â†’    STAGING    â†’    PROD      â”‚
â”‚                                                             â”‚
â”‚  Developer      QA Team         Pre-prod         Live       â”‚
â”‚  testing        testing         validation       system     â”‚
â”‚                                                             â”‚
â”‚  Mock data      Test data       Prod-like        Real data  â”‚
â”‚  Local          Shared          Isolated         HA/DR      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.2 Test Data Management

**Strategies:**
1. **Production clone** (masked for privacy)
2. **Synthetic data generation**
3. **Subset of production**
4. **Manual creation**

**Data Masking Example:**
```
Original:   John Smith    john@email.com    4532-1234-5678-9012
Masked:     Xxxx Xxxxx    xxx@xxxxx.xxx     4532-XXXX-XXXX-XXXX
```

---

## 9. Quick Reference Tables

### 9.1 Test Types Summary

| Type | When | Who | Scope |
|------|------|-----|-------|
| Smoke | New build | Dev/QA | Critical paths |
| Sanity | Bug fix | QA | Changed module |
| Regression | Any change | QA/Auto | All/selected |
| Exploratory | New feature | QA | Undefined |
| UAT | Pre-release | Users | Business reqs |

### 9.2 SDLC Model Comparison

| Aspect | Waterfall | V-Model | Agile |
|--------|-----------|---------|-------|
| Testing phase | End | Parallel | Continuous |
| Flexibility | Low | Low | High |
| Documentation | Heavy | Heavy | Light |
| Customer involvement | Low | Low | High |
| Risk discovery | Late | Medium | Early |
| Best for | Fixed reqs | Critical systems | Evolving reqs |

### 9.3 Severity vs Priority

| | Critical | High | Medium | Low |
|---|---|---|---|---|
| **P1** | Fix now | Fix now | - | - |
| **P2** | Next release | Next release | Fix soon | - |
| **P3** | - | Backlog | Backlog | Backlog |
| **P4** | - | - | Nice to have | Nice to have |

---

## 10. Shift-Left Testing & DevSecOps (2025 Update)

### 10.1 Shift-Left Testing

**Concept:** Move testing earlier in the SDLC to find bugs when they're cheaper to fix.

```
Traditional:
Requirements â†’ Design â†’ Code â†’ Test â†’ Deploy
                              â†‘
                         Testing here (expensive)

Shift-Left:
Requirements â†’ Design â†’ Code â†’ Test â†’ Deploy
     â†‘            â†‘       â†‘
  Testing    Testing  Testing (cheaper)
```

**Cost of Defects:**

| Phase Found | Cost Multiplier |
|-------------|-----------------|
| Requirements | 1x |
| Design | 5x |
| Coding | 10x |
| Testing | 20x |
| Production | 100x+ |

**Shift-Left Practices:**

| Practice | Description |
|----------|-------------|
| **TDD** | Write tests before code |
| **BDD** | Define behavior with stakeholders first |
| **Static Analysis** | Lint/scan code during development |
| **Pair Programming** | Real-time code review |
| **CI/CD Testing** | Automated tests on every commit |

### 10.2 DevSecOps

**Concept:** Integrate security into DevOps pipeline (Security as Code).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DevSecOps Pipeline                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  PLAN      CODE       BUILD      TEST      DEPLOY    MONITORâ”‚
â”‚    â”‚         â”‚          â”‚          â”‚          â”‚          â”‚  â”‚
â”‚    â–¼         â–¼          â–¼          â–¼          â–¼          â–¼  â”‚
â”‚ Threat    SAST      Dependency  DAST     Container   SIEM   â”‚
â”‚ Modeling  SCA       Scanning    Pentest  Scanning    Alerts â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Security Testing Types:**

| Type | When | Tools |
|------|------|-------|
| **SAST** (Static) | Code phase | SonarQube, Semgrep, CodeQL |
| **SCA** (Composition) | Build phase | Snyk, OWASP Dependency-Check |
| **DAST** (Dynamic) | Test phase | OWASP ZAP, Burp Suite |
| **IAST** (Interactive) | Runtime | Contrast Security |

**SAST Example (GitHub Actions):**
```yaml
name: Security Scan
on: [push, pull_request]

jobs:
  sast:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Run Semgrep
        uses: semgrep/semgrep-action@v1
        with:
          config: auto

      - name: Run CodeQL
        uses: github/codeql-action/analyze@v3
```

**SCA Example:**
```yaml
  dependency-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Snyk Security Scan
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high
```

### 10.3 Testing in CI/CD Pipeline

**Recommended Test Stages:**

```yaml
# .github/workflows/test.yml
name: Test Pipeline

on: [push]

jobs:
  # Stage 1: Fast feedback (< 5 min)
  unit-tests:
    runs-on: ubuntu-latest
    steps:
      - run: npm test

  # Stage 2: Integration (< 15 min)
  integration-tests:
    needs: unit-tests
    runs-on: ubuntu-latest
    steps:
      - run: npm run test:integration

  # Stage 3: Security (parallel)
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - run: npm audit
      - uses: snyk/actions/node@master

  # Stage 4: E2E (< 30 min)
  e2e-tests:
    needs: [unit-tests, integration-tests]
    runs-on: ubuntu-latest
    steps:
      - run: npx playwright test
```

**Test Stage Recommendations:**

| Stage | Tests | Time | Blocker |
|-------|-------|------|---------|
| Pre-commit | Lint, unit | < 30s | Yes |
| CI | Unit, integration | < 10min | Yes |
| Staging | E2E, performance | < 30min | Yes |
| Production | Smoke, monitoring | < 5min | Alert |

---

## 11. Common Exam Topics Checklist

```markdown
â–¡ SDLC models (Waterfall, V-Model, Agile)
â–¡ Test levels (Unit, Integration, System, Acceptance)
â–¡ Test types (Smoke, Sanity, Regression, Exploratory)
â–¡ Test documentation (Plan, Case, Report)
â–¡ Black-box techniques (ECP, BVA, Decision Table)
â–¡ White-box techniques (Statement, Branch, Path coverage)
â–¡ Defect lifecycle and reporting
â–¡ Test metrics and formulas
â–¡ Manual vs Automation decision
â–¡ Agile testing practices
â–¡ Shift-left testing (TDD, BDD, early testing)
â–¡ DevSecOps (SAST, SCA, DAST integration)
```

---

*Good luck vá»›i ká»³ thi! ğŸ“*
